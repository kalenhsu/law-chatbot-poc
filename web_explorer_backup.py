import streamlit as st
from langchain.callbacks.base import BaseCallbackHandler
from langchain.chains import RetrievalQAWithSourcesChain
from langchain.prompts import ChatMessagePromptTemplate, PromptTemplate

from WebRetrieverAccelerate.my_web_research import WebResearchRetriever

from dotenv import load_dotenv
import json
import logging
import os
import requests

# %%
st.set_page_config(page_title="test search", page_icon="ğŸŒ")


def settings():
    # Vectorstore
    import faiss
    from langchain.vectorstores import FAISS
    from langchain.embeddings.openai import OpenAIEmbeddings
    from langchain.docstore import InMemoryDocstore
    embeddings_model = OpenAIEmbeddings(deployment=os.environ["OPENAI_EMBEDDING_ENGINE"])
    embedding_size = 1536
    index = faiss.IndexFlatL2(embedding_size)
    vectorstore_public = FAISS(embeddings_model.embed_query, index, InMemoryDocstore({}), {})

    # LLM
    from langchain.chat_models import AzureChatOpenAI
    openai_llm = AzureChatOpenAI(
        openai_api_base=os.environ["OPENAI_API_BASE"],
        openai_api_version=os.environ["OPENAI_API_VERSION"],
        deployment_name=os.environ["OPENAI_ENGINE"],
        openai_api_key=os.environ["OPENAI_API_KEY"],
        openai_api_type=os.environ["OPENAI_API_TYPE"],
    )

    # Search
    from langchain.utilities import GoogleSearchAPIWrapper
    search = GoogleSearchAPIWrapper()

    # Initialize 
    web_retriever_with_openai = WebResearchRetriever.from_llm(
        vectorstore=vectorstore_public,
        llm=openai_llm,
        search=search,
        num_search_results=5
    )

    return web_retriever_with_openai, openai_llm


class StreamHandler(BaseCallbackHandler):
    def __init__(self, container, initial_text=""):
        self.container = container
        self.text = initial_text

    def on_llm_new_token(self, token: str, **kwargs) -> None:
        self.text += token
        self.container.info(self.text)


class PrintRetrievalHandler(BaseCallbackHandler):
    def __init__(self, container):
        self.container = container.expander("Context Retrieval")

    def on_retriever_start(self, query: str, **kwargs):
        self.container.write(f"**Question:** {query}")

    def on_retriever_end(self, documents, **kwargs):
        # self.container.write(documents)
        for idx, doc in enumerate(documents):
            source = doc.metadata["source"]
            self.container.write(f"**Results from {source}**")
            self.container.text(doc.page_content)


def query_with_button_value(input_value, llm, web_retriever, role):
    output_prompt = \
        f"ç¾åœ¨ä½ æ˜¯ä¸€å€‹{role['position']}çš„è§’è‰²ï¼Œæœƒç”¨{role['tone']}çš„å£å»å›ç­”å•é¡Œã€‚\n" \
        + "ç•¶æœ‰ç”¨æˆ¶è©¢å•çš„å•é¡Œæ˜¯ã€Œ" + input_value + """ã€ï¼Œ
        
        ä¸”ä½ æŸ¥è©¢åˆ°çš„è³‡æ–™æ˜¯ï¼š
    
        {summaries}
    
        è«‹åƒè€ƒä¸Šè¿°å•é¡ŒåŠè³‡æ–™ï¼Œä½¿ç”¨ç¹é«”ä¸­æ–‡ã€ä»¥åˆ—é»çš„æ–¹å¼ï¼Œç”¨""" + role['tone'] + """çš„å£å»å›è¦†ç”¨æˆ¶ã€‚
        è‹¥æŸ¥è©¢åˆ°çš„è³‡æ–™ä¸è¶³ä»¥å›ç­”ï¼Œè«‹èªªæ˜ç„¡æ³•å›ç­”çš„åŸå› ã€ä¸¦åˆ—èˆ‰å»ºè­°ä¹‹æå•ã€‚
        """
    output_prompt_template = PromptTemplate(template=output_prompt, input_variables=["summaries"])

    # Set up logging
    logging.basicConfig()
    logging.getLogger("langchain.retrievers.web_research").setLevel(logging.INFO)

    qa_chain = RetrievalQAWithSourcesChain.from_chain_type(llm, retriever=web_retriever,
                                                           chain_type_kwargs={"prompt": output_prompt_template})

    # Write answer and sources
    output_answer = st.empty()
    placeholder = st.empty()
    placeholder.text("è©¢å•ä¸­ï¼Œè«‹ç¨å€™...")
    stream_handler = StreamHandler(output_answer, initial_text="`Answer:`\n\n")

    try:
        with open("role-setting.json") as j:
            disclaimer_info = json.load(j)
        result = qa_chain({"question": f"{input_value}ï¼Ÿ {os.environ['question']}"}, callbacks=[stream_handler])
        placeholder.empty()
        output_answer.info("`å›ç­”:`\n\n" + result["answer"] \
                           + f"\n\nä»¥ä¸Šè³‡è¨Šåƒ…ä¾›åƒè€ƒï¼Œå¦‚æœ‰éœ€è¦æ›´ç²¾æº–è³‡è¨Šè«‹è«®è©¢å°ˆæ¥­å¾‹å¸«æˆ–{disclaimer_info['æœå‹™å–®ä½']}æœå‹™åœ˜éšŠã€‚" \
                           + f"\n\n{disclaimer_info['æœå‹™å–®ä½']}é›»è©±ï¼š{disclaimer_info['æœå‹™é›»è©±']}" \
                           + f"\n\n{disclaimer_info['æœå‹™å–®ä½']}å®˜ç¶²ï¼š{disclaimer_info['æœå‹™å®˜ç¶²']}")

    except requests.Timeout as timeErr:
        placeholder.empty()
        output_answer.info("`è­¦å‘Šè¨Šæ¯:`\n\n" + "éå¸¸æŠ±æ­‰ï¼Œç•¶å‰ä¼ºæœå™¨éæ–¼æ“æ“ ã€‚\nè«‹ç¨å¾…ä¸€æ®µæ™‚é–“ã€ä¸¦é‡æ–°æ•´ç†é é¢å†åšå˜—è©¦ã€‚")
        print(timeErr)

    except Exception as e:
        placeholder.empty()
        output_answer.info("`è­¦å‘Šè¨Šæ¯:`\n\n" + "éå¸¸æŠ±æ­‰ï¼Œç•¶å‰ç³»çµ±é­é‡åˆ°å•é¡Œã€‚\nè«‹ç¨å¾…ä¸€æ®µæ™‚é–“ã€ä¸¦é‡æ–°æ•´ç†é é¢å†åšå˜—è©¦ã€‚")
        print(e)

    return True


def query_with_button_value2(input_value, llm, web_retriever, role):
    output_prompt = \
        f"ç¾åœ¨ä½ æ˜¯ä¸€å€‹{role['position']}çš„è§’è‰²ï¼Œæœƒç”¨{role['tone']}çš„å£å»å›ç­”å•é¡Œã€‚\n" \
        + "ç•¶æœ‰ç”¨æˆ¶è©¢å•çš„å•é¡Œæ˜¯ã€Œ" + input_value + """  æå½¥ç§€ä½¿å¦å°è©²è­°é¡Œæœ‰è²¢ç»ï¼Ÿã€ï¼Œ
        
        ä¸”ä½ æŸ¥è©¢åˆ°çš„è³‡æ–™æ˜¯ï¼š
    
        {summaries}
    
        è«‹åƒè€ƒä¸Šè¿°å•é¡ŒåŠè³‡æ–™ï¼Œä½¿ç”¨ç¹é«”ä¸­æ–‡ã€ä»¥åˆ—é»çš„æ–¹å¼ï¼Œç”¨""" + role['tone'] + """çš„å£å»å›è¦†ç”¨æˆ¶ã€‚
        è‹¥æŸ¥è©¢åˆ°çš„è³‡æ–™ä¸è¶³ä»¥å›ç­”ï¼Œè«‹èªªæ˜ç„¡æ³•å›ç­”çš„åŸå› ã€ä¸¦åˆ—èˆ‰å»ºè­°ä¹‹æå•ã€‚
        """
    output_prompt_template = PromptTemplate(template=output_prompt, input_variables=["summaries"])

    # Set up logging
    logging.basicConfig()
    logging.getLogger("langchain.retrievers.web_research").setLevel(logging.INFO)

    qa_chain = RetrievalQAWithSourcesChain.from_chain_type(llm, retriever=web_retriever,
                                                           chain_type_kwargs={"prompt": output_prompt_template})

    # Write answer and sources
    output_answer = st.empty()
    placeholder = st.empty()
    placeholder.text("è©¢å•ä¸­ï¼Œè«‹ç¨å€™...")
    stream_handler = StreamHandler(output_answer, initial_text="`Answer:`\n\n")

    try:
        with open("role-setting.json") as j:
            disclaimer_info = json.load(j)
        result = qa_chain({"question": f"{input_value} æå½¥ç§€çš„è²¢ç»ç‚ºä½•ï¼Ÿ"}, callbacks=[stream_handler])
        placeholder.empty()
        output_answer.info("`å›ç­”:`\n\n" + result["answer"] \
                           + f"\n\nä»¥ä¸Šè³‡è¨Šåƒ…ä¾›åƒè€ƒï¼Œå¦‚æœ‰éœ€è¦æ›´ç²¾æº–è³‡è¨Šè«‹è«®è©¢å°ˆæ¥­å¾‹å¸«æˆ–{disclaimer_info['æœå‹™å–®ä½']}æœå‹™åœ˜éšŠã€‚" \
                           + f"\n\n{disclaimer_info['æœå‹™å–®ä½']}é›»è©±ï¼š{disclaimer_info['æœå‹™é›»è©±']}" \
                           + f"\n\n{disclaimer_info['æœå‹™å–®ä½']}å®˜ç¶²ï¼š{disclaimer_info['æœå‹™å®˜ç¶²']}")

    except requests.Timeout as timeErr:
        placeholder.empty()
        output_answer.info("`è­¦å‘Šè¨Šæ¯:`\n\n" + "éå¸¸æŠ±æ­‰ï¼Œç•¶å‰ä¼ºæœå™¨éæ–¼æ“æ“ ã€‚\nè«‹ç¨å¾…ä¸€æ®µæ™‚é–“ã€ä¸¦é‡æ–°æ•´ç†é é¢å†åšå˜—è©¦ã€‚")
        print(timeErr)

    except Exception as e:
        placeholder.empty()
        output_answer.info("`è­¦å‘Šè¨Šæ¯:`\n\n" + "éå¸¸æŠ±æ­‰ï¼Œç•¶å‰ç³»çµ±é­é‡åˆ°å•é¡Œã€‚\nè«‹ç¨å¾…ä¸€æ®µæ™‚é–“ã€ä¸¦é‡æ–°æ•´ç†é é¢å†åšå˜—è©¦ã€‚")
        print(e)

    return True


# %%
load_dotenv()

# Make retriever and llm
if "retriever" not in st.session_state:
    st.session_state["retriever"], st.session_state["llm"] = settings()
my_retriever = st.session_state.retriever
my_llm = st.session_state.llm

# User input
st.title("åœ‹çœ¾æ³•å¾‹èŠå¤©æ©Ÿå™¨äºº")
st.header("Leosys Law Chatbot\n")
option_role = {
    "position": st.selectbox("è«‹é¸æ“‡æ‚¨æœŸæœ›çš„æœå‹™è§’è‰²", ("å°ˆæ¥­å¾‹å¸«", "ç«‹æ³•å§”å“¡", "é«˜ç´šå·¥ç¨‹å¸«")),
    "tone": st.selectbox("è«‹é¸æ“‡æ‚¨æœŸæœ›çš„æœå‹™å£å»", ("å’Œè—¹è¦ªåˆ‡", "å°ˆæ¥­å†·é…·", "ç†±æƒ…é–‹æ”¾"))
}
init_status = 0
input_text_container = st.empty()
question = input_text_container.text_input("`è«‹è¼¸å…¥æ‚¨çš„å•é¡ŒğŸ‘‡`")
example_question_1 = st.button("å»ºè­°å•é¡Œï¼šå¹¾æœˆç¹³ç‰Œç…§ç¨…ï¼Ÿ")
example_question_2 = st.button("å»ºè­°å•é¡Œï¼šé…’é§•ç½°å¤šå°‘ï¼Ÿ")
example_question_3 = st.button("å»ºè­°å•é¡Œï¼šç¶²è·¯è³¼ç‰©å¯ä»¥é€€è²¨å—ï¼Ÿ")

if example_question_1:
    input_text_container.text_input("`è«‹è¼¸å…¥æ‚¨çš„å•é¡ŒğŸ‘‡`", "å¹¾æœˆç¹³ç‰Œç…§ç¨…ï¼Ÿ")
    query_with_button_value("å¹¾æœˆç¹³ç‰Œç…§ç¨…ï¼Ÿ", my_llm, my_retriever, option_role)
    question = False

if example_question_2:
    input_text_container.text_input("`è«‹è¼¸å…¥æ‚¨çš„å•é¡ŒğŸ‘‡`", "é…’é§•ç½°å¤šå°‘ï¼Ÿ")
    query_with_button_value("é…’é§•ç½°å¤šå°‘ï¼Ÿ", my_llm, my_retriever, option_role)
    question = False

if example_question_3:
    input_text_container.text_input("`è«‹è¼¸å…¥æ‚¨çš„å•é¡ŒğŸ‘‡`", "ç¶²è·¯è³¼ç‰©å¯ä»¥é€€è²¨å—ï¼Ÿ")
    query_with_button_value("ç¶²è·¯è³¼ç‰©å¯ä»¥é€€è²¨å—ï¼Ÿ", my_llm, my_retriever, option_role)
    question = False

if question and (question not in ["å¹¾æœˆç¹³ç‰Œç…§ç¨…ï¼Ÿ", "é…’é§•ç½°å¤šå°‘ï¼Ÿ", "ç¶²è·¯è³¼ç‰©å¯ä»¥é€€è²¨å—ï¼Ÿ"]):
    query_with_button_value(question, my_llm, my_retriever, option_role)
    question = False
