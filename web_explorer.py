import streamlit as st
from langchain.callbacks.base import BaseCallbackHandler
from langchain.chains import RetrievalQAWithSourcesChain
from langchain.prompts import PromptTemplate
from langchain.schema import HumanMessage

from WebRetrieverAccelerate.my_web_research import WebResearchRetriever

from dotenv import load_dotenv
import json
import logging
import os
import requests
import time

# %%
st.set_page_config(page_title="test search", page_icon="ğŸŒ")


def settings():
    # Vectorstore
    import faiss
    from langchain.vectorstores import FAISS
    from langchain.embeddings.openai import OpenAIEmbeddings
    from langchain.docstore import InMemoryDocstore
    embeddings_model = OpenAIEmbeddings(deployment=os.environ["OPENAI_EMBEDDING_ENGINE"])
    embedding_size = 1536
    index = faiss.IndexFlatL2(embedding_size)
    vectorstore_public = FAISS(embeddings_model.embed_query, index, InMemoryDocstore({}), {})

    # LLM
    from langchain.chat_models import AzureChatOpenAI
    openai_llm = AzureChatOpenAI(
        openai_api_base=os.environ["OPENAI_API_BASE"],
        openai_api_version=os.environ["OPENAI_API_VERSION"],
        deployment_name=os.environ["OPENAI_ENGINE"],
        openai_api_key=os.environ["OPENAI_API_KEY"],
        openai_api_type=os.environ["OPENAI_API_TYPE"],
        streaming=True,
    )

    # Search
    from langchain.utilities import GoogleSearchAPIWrapper
    search = GoogleSearchAPIWrapper()

    # Initialize 
    web_retriever_with_openai = WebResearchRetriever.from_llm(
        vectorstore=vectorstore_public,
        llm=openai_llm,
        search=search,
        num_search_results=4
    )

    return web_retriever_with_openai, openai_llm


class StreamHandler(BaseCallbackHandler):
    def __init__(self, container, initial_text=""):
        self.container = container
        self.text = initial_text

    def on_llm_new_token(self, token: str, **kwargs) -> None:
        self.text += token
        self.container.info(self.text)


class PrintRetrievalHandler(BaseCallbackHandler):
    def __init__(self, container):
        self.container = container.expander("Context Retrieval")

    def on_retriever_start(self, query: str, **kwargs):
        self.container.write(f"**Question:** {query}")

    def on_retriever_end(self, documents, **kwargs):
        # self.container.write(documents)
        for idx, doc in enumerate(documents):
            source = doc.metadata["source"]
            self.container.write(f"**Results from {source}**")
            self.container.text(doc.page_content)


def check_similar_politics(politics_doc, input_q, llm):
    with open(politics_doc) as j:
        politics = json.load(j)
    n_politics = str(len(politics.keys()))
    politics = "\n\n".join([
        title+"ï¼š\n"+str(politics[title]).replace("', '", "\n")[2:-2] for title in politics.keys()
    ])
    politics_prompt = f"{politics}\n\nè«‹å•ä»¥ä¸Š{n_politics}"+"""é»æ”¿è¦‹ï¼Œä½•è€…è·Ÿã€Œ{question}ã€æœ€æœ‰é—œè¯ï¼Ÿ
            
            è«‹åœ¨ç¬¬ä¸€è¡ŒåŠ ä¸Šã€Œæœ‰é—œè¯ã€ä¸‰å€‹å­—ã€ä¸¦åœ¨ç¬¬äºŒè¡Œå°‡æœ€æœ‰é—œçš„æ”¿è¦‹å°å‡ºï¼Œä¸¦åœ¨ç¬¬ä¸‰è¡Œä»¥ä¸€ç™¾äº”åå­—ä»¥å…§è§£é‡‹å…©è€…ä¹‹é–“å¦‚ä½•é—œè¯ã€‚
            è‹¥å…¨éƒ¨éƒ½ç„¡é—œçš„è©±åœ¨ç¬¬ä¸€è¡ŒåŠ ä¸Šã€Œç„¡é—œè¯ã€ä¸‰å€‹å­—ã€‚
            """.format(question=input_q)
    politics_msg = HumanMessage(content=politics_prompt)
    result = llm(messages=[politics_msg]).to_json()["kwargs"]["content"]

    return result


def query_with_button_value(input_value, llm, web_retriever):
    ttl_start_time = time.time()
    with open("role-setting.json") as j:
        role_setting_info = json.load(j)

    output_prompt = \
        f"è«‹æ‰®æ¼”ä¸€å€‹å°ç£åœ°å€çš„{role_setting_info['æœå‹™è§’è‰²']}çš„è§’è‰²ï¼Œæœƒç”¨{role_setting_info['æœå‹™å£å»']}çš„å£å»å›ç­”å•é¡Œã€‚\n" \
        + "ç•¶ç”¨æˆ¶è©¢å•çš„å•é¡Œæ˜¯ã€Œ" + input_value + """ã€ï¼Œ
        
        ä¸”ä½ æŸ¥è©¢åˆ°çš„è³‡æ–™æ˜¯ï¼š
    
        {summaries}
    
        è«‹åƒè€ƒä¸Šè¿°å•é¡ŒåŠè³‡æ–™ï¼Œæ–¼å››ç™¾å­—ä»¥å…§ã€ä½¿ç”¨ç¹é«”ä¸­æ–‡ã€ä»¥åˆ—é»çš„æ–¹å¼ï¼Œç”¨""" + role_setting_info['æœå‹™å£å»'] + """çš„å£å»å›è¦†ç”¨æˆ¶çš„æ‰€æœ‰å•é¡Œã€‚
        è‹¥æŸ¥è©¢åˆ°çš„è³‡æ–™ä¸è¶³ä»¥å›ç­”ï¼Œè«‹èªªæ˜ç„¡æ³•å›ç­”çš„åŸå› ã€ä¸¦åˆ—èˆ‰å»ºè­°ä¹‹æå•ã€‚
        """
    output_prompt_template = PromptTemplate(template=output_prompt, input_variables=["summaries"])

    # Set up logging
    logging.basicConfig()
    logging.getLogger("langchain.retrievers.web_research").setLevel(logging.INFO)

    qa_chain = RetrievalQAWithSourcesChain.from_chain_type(llm, retriever=web_retriever,
                                                           chain_type_kwargs={"prompt": output_prompt_template})

    # Write answer and sources
    output_answer = st.empty()
    placeholder = st.empty()
    placeholder.text("è©¢å•ä¸­ï¼Œè«‹ç¨å€™...")
    stream_handler = StreamHandler(output_answer, initial_text="`Answer:`\n\n")

    try:
        result = qa_chain({"question": f"{input_value} {os.environ['question']}"},
                          callbacks=[stream_handler])
        output_answer.info("`å›ç­”:`\n\n" + result["answer"] \
                           + f"\n\nä»¥ä¸Šè³‡è¨Šåƒ…ä¾›åƒè€ƒï¼Œå¦‚æœ‰éœ€è¦æ›´ç²¾æº–è³‡è¨Šè«‹è«®è©¢å°ˆæ¥­å¾‹å¸«æˆ–{role_setting_info['æœå‹™å–®ä½']}æœå‹™åœ˜éšŠã€‚" \
                           + f"\n\n{role_setting_info['æœå‹™å–®ä½']}é›»è©±ï¼š{role_setting_info['æœå‹™é›»è©±']}" \
                           + f"\n\n{role_setting_info['æœå‹™å–®ä½']}å®˜ç¶²ï¼š{role_setting_info['æœå‹™å®˜ç¶²']}")
        print("--- Basic Answering in %s seconds ---" % (time.time() - ttl_start_time))

        politics_result = check_similar_politics(politics_doc="politics.json", input_q=input_value, llm=llm)
        print("check_similar_politics: ", politics_result)
        if politics_result[:3] == "æœ‰é—œè¯":
            politics_result = politics_result[3:].replace('\n', '\n\n')
            st.info('`Note:`\n\n' \
                    + f"ä»¥ä¸Šæå•ã€Œ{input_value}ã€èˆ‡{role_setting_info['æœå‹™å–®ä½']}ä¹‹æ”¿è¦‹æœ‰é—œè¯ã€‚\n" \
                    + f"\n\n{role_setting_info['æœå‹™å–®ä½']}æ›¾ç¶“æå‡ºï¼š{politics_result}")
        placeholder.empty()

    except requests.Timeout as timeErr:
        placeholder.empty()
        output_answer.info("`è­¦å‘Šè¨Šæ¯:`\n\n" + "éå¸¸æŠ±æ­‰ï¼Œç•¶å‰ä¼ºæœå™¨éæ–¼æ“æ“ ã€‚\nè«‹ç¨å¾…ä¸€æ®µæ™‚é–“ã€ä¸¦é‡æ–°æ•´ç†é é¢å†åšå˜—è©¦ã€‚")
        print(timeErr)

    except Exception as e:
        placeholder.empty()
        output_answer.info("`è­¦å‘Šè¨Šæ¯:`\n\n" + "éå¸¸æŠ±æ­‰ï¼Œç•¶å‰ç³»çµ±é­é‡åˆ°å•é¡Œã€‚\nè«‹ç¨å¾…ä¸€æ®µæ™‚é–“ã€ä¸¦é‡æ–°æ•´ç†é é¢å†åšå˜—è©¦ã€‚")
        print(e)

    print("--- Total Running in %s seconds ---" % (time.time() - ttl_start_time))
    print("Done. \n\n")

    return True


# %% Streamlit Run
load_dotenv()

# Make retriever and llm
if "retriever" not in st.session_state:
    st.session_state["retriever"], st.session_state["llm"] = settings()
my_retriever = st.session_state.retriever
my_llm = st.session_state.llm

# User input
st.title("åœ‹çœ¾æ³•å¾‹èŠå¤©æ©Ÿå™¨äºº")
st.header("Leosys Law Chatbot\n")
input_text_container = st.empty()
question = input_text_container.text_input("`è«‹è¼¸å…¥æ‚¨çš„å•é¡ŒğŸ‘‡`")
example_question_1 = st.button("å»ºè­°å•é¡Œï¼šå¹¾æœˆç¹³æ±½æ©Ÿè»Šç‰Œç…§ç¨…ï¼Ÿ")
example_question_2 = st.button("å»ºè­°å•é¡Œï¼šé…’é§•ç½°å¤šå°‘ï¼Ÿ")
example_question_3 = st.button("å»ºè­°å•é¡Œï¼šç¶²è·¯è³¼ç‰©å¯ä»¥é€€è²¨å—ï¼Ÿ")

if example_question_1:
    input_text_container.text_input("`è«‹è¼¸å…¥æ‚¨çš„å•é¡ŒğŸ‘‡`", "å¹¾æœˆç¹³æ±½æ©Ÿè»Šç‰Œç…§ç¨…ï¼Ÿ")
    query_with_button_value("å¹¾æœˆç¹³æ±½æ©Ÿè»Šç‰Œç…§ç¨…ï¼Ÿ", my_llm, my_retriever)
    question = False

if example_question_2:
    input_text_container.text_input("`è«‹è¼¸å…¥æ‚¨çš„å•é¡ŒğŸ‘‡`", "é…’é§•ç½°å¤šå°‘ï¼Ÿ")
    query_with_button_value("é…’é§•ç½°å¤šå°‘ï¼Ÿ", my_llm, my_retriever)
    question = False

if example_question_3:
    input_text_container.text_input("`è«‹è¼¸å…¥æ‚¨çš„å•é¡ŒğŸ‘‡`", "ç¶²è·¯è³¼ç‰©å¯ä»¥é€€è²¨å—ï¼Ÿ")
    query_with_button_value("ç¶²è·¯è³¼ç‰©å¯ä»¥é€€è²¨å—ï¼Ÿ", my_llm, my_retriever)
    question = False

if question and (question not in ["å¹¾æœˆç¹³æ±½æ©Ÿè»Šç‰Œç…§ç¨…ï¼Ÿ", "é…’é§•ç½°å¤šå°‘ï¼Ÿ", "ç¶²è·¯è³¼ç‰©å¯ä»¥é€€è²¨å—ï¼Ÿ"]):
    query_with_button_value(question, my_llm, my_retriever)
    question = False
